{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1386555,"sourceType":"datasetVersion","datasetId":809358}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nwith_mask_files= os.listdir(\"/kaggle/input/face-mask-dataset/data/with_mask\")\nwithout_mask_files=os.listdir(\"/kaggle/input/face-mask-dataset/data/without_mask\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=mpimg.imread(\"/kaggle/input/face-mask-dataset/data/without_mask/without_mask_89.jpg\")\nimgplot=plt.imshow(img)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img=mpimg.imread(\"/kaggle/input/face-mask-dataset/data/with_mask/with_mask_100.jpg\")\nimgplot=plt.imshow(img)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Data Preprocessing (Image Processing (Resizing all images to same size))**","metadata":{}},{"cell_type":"code","source":"with_mask_path=\"/kaggle/input/face-mask-dataset/data/with_mask/\"\nwithout_mask_path=\"/kaggle/input/face-mask-dataset/data/without_mask/\"\n\ndata=[]\n\nfor img in with_mask_files:\n    image=Image.open(with_mask_path+img)\n    image=image.resize((128,128))\n    image=image.convert(\"RGB\")\n    image=np.array(image)\n    data.append(image)\nfor img in without_mask_files:\n    image=Image.open(without_mask_path+img)\n    image=image.resize((128,128))\n    image=image.convert(\"RGB\")\n    image=np.array(image)\n    data.append(image)\n\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Making Labels**","metadata":{}},{"cell_type":"code","source":"len(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with_mask_labels = [1]*3725  \nwithout_mask_labels = [0]*3828\nY = with_mask_labels + without_mask_labels\nprint(len(Y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Train Test Split Data**","metadata":{}},{"cell_type":"code","source":"X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape,X_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Scaling the dataset**","metadata":{}},{"cell_type":"code","source":"X_train_scaled=X_train/255\nX_test_scaled=X_test/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Building a Convulational Neural Network (CNN)**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nmodel = keras.Sequential()\n\nmodel.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n\n\nmodel.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(keras.layers.Flatten())\n\nmodel.add(keras.layers.Dense(128, activation='relu'))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.Dense(64, activation='relu'))\nmodel.add(keras.layers.Dropout(0.5))\nmodel.add(keras.layers.Dense(2, activation='sigmoid'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['acc'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"\n\n**Evaluation**","metadata":{}},{"cell_type":"code","source":"\n\n# from google.colab.patches import cv2_imshow \ninput_image_path = input('Path of the image to be predicted: ')\n\ninput_image = cv2.imread(input_image_path)\n\n# cv2_imshow(input_image)\n\nplt.imshow(input_image)\nplt.axis('off')\nplt.show()\n# input_image_resized = cv2.resize(input_image, (128,128))\n\ninput_image_scaled = input_image_resized/255\n\ninput_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n\ninput_prediction = model.predict(input_image_reshaped)\n\nprint(input_prediction)\n\n\ninput_pred_label = np.argmax(input_prediction)\n\nprint(input_pred_label)\n\n\nif input_pred_label == 1:\n\n  print('The person in the image is wearing a mask')\n\nelse:\n\n  print('The person in the image is not wearing a mask')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}